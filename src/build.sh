#!/bin/bash

function help_menu {
    ### Displays help menu ###
    echo "Usage: ./build.sh COMMAND"
    echo ""
    echo "Commands:"
    echo "clean         Removes all the generated files"
    echo "generate      Generate the training, testing and their word aligned files from the parallel corpus"
    echo "train         Train the Phrase-Based Statistical Machine Translation model"
    echo "test          Run the model on the testset and Evaluate the translations generated by the model"
    echo "build         Build the whole PBSMT model by performing clean, generate and train together"
    echo "help          Display help menu"
}

function clean_files {
    ### Clean the files built by previous run of the model ###
    echo "Cleaning in progress..."
    rm -rf  Dataset/raw  Dataset/intermediate  Dataset/processed  Dataset/*.txt  Dataset/*.lm  Dataset/  ./*.txt 
}

function generate_data {
    ### Generates the files required by the PBSMT model ###
    export STANFORD_PARSER_HOME=/home/aman-anmol/Documents/3-II/StatisticalMethodsInAI/Assignments/machine-translator/src/utils/stanford-parser-full-2018-10-17
    
    # Word Alignment 
    echo "Word Alignment in progress..."
    mkdir -p Dataset/raw Dataset/intermediate Dataset/processed

    python3 preprocess_parallel.py ./data-files/parallel/training.en ./data-files/parallel/training.hi 1.0
    ./utils/cfilt_preorder/reorderEnglish.sh Dataset/raw/training_source.txt hindi_tuned
    cp Dataset/raw/training_source.txt.codkilled.v1.0 Dataset/raw/training_source.txt

    python3 postprocess.py ./Dataset/raw/training_source.txt ./Dataset/raw/training_target.txt
    python3 bilingual_dict_preprocess.py ./data-files/English-Hindi/adj.txt ./data-files/English-Hindi/adv.txt ./data-files/English-Hindi/noun.txt ./data-files/English-Hindi/verb.txt

    ./utils/plain2snt.out Dataset/raw/training_source.txt Dataset/raw/training_target.txt
    mv Dataset/raw/*.vcb Dataset/intermediate
    mv Dataset/raw/*.snt Dataset/intermediate

    ./utils/mkcls -p./Dataset/raw/training_source.txt -V./Dataset/intermediate/training_source.vcb.classes 
    ./utils/mkcls -p./Dataset/raw/training_target.txt -V./Dataset/intermediate/training_target.vcb.classes 

    ./utils/GIZA++ -s Dataset/intermediate/training_source.vcb -t Dataset/intermediate/training_target.vcb -c Dataset/intermediate/training_source_training_target.snt -o source-alignment -outputpath Dataset/processed
    ./utils/GIZA++ -s Dataset/intermediate/training_target.vcb -t Dataset/intermediate/training_source.vcb -c Dataset/intermediate/training_target_training_source.snt -o target-alignment -outputpath Dataset/processed

    cp Dataset/processed/source-alignment.A3.final Dataset/source-alignment.txt
    cp Dataset/processed/target-alignment.A3.final Dataset/target-alignment.txt

    # Language Model 
    echo "Language Model generation in progress..."
    #python3 preprocess_monolingual.py data-files/dev_test/dev.en Dataset/raw/training_s.txt
    python3 preprocess_monolingual.py data-files/monolingual/final-mono.hi Dataset/raw/training_t.txt

    #tar -czvf Dataset/raw/training_s.gz Dataset/raw/training_s.txt
    tar -czvf Dataset/raw/training_t.gz Dataset/raw/training_t.txt

    #./utils/ngt -i="gunzip -c Dataset/raw/training_s.gz" -n=3 -o=Dataset/intermediate/training_s.www -b=yes
    ./utils/ngt -i="gunzip -c Dataset/raw/training_t.gz" -n=3 -o=Dataset/intermediate/training_t.www -b=yes
    #./utils/tlm -tr=Dataset/intermediate/training_s.www -n=3 -lm=wb -o=Dataset/processed/training_s.lm
    ./utils/tlm -tr=Dataset/intermediate/training_t.www -n=3 -lm=wb -o=Dataset/processed/training_t.lm
    #cp Dataset/processed/training_s.lm Dataset/training_s.lm
    cp Dataset/processed/training_t.lm Dataset/training_t.lm
}

function train_model {
    ### Train the PBSMT model on the generated files ###
    echo "Training in progress..."
    
    # Model Training 
    python3 phrase_extraction.py ./Dataset/source-alignment.txt ./Dataset/target-alignment.txt
    python3 translation_probability.py ./phrases.txt
    #python3 phrase_table_generation.py translationProbabilityTargetGivenSource.txt ./Dataset/training_s.lm ./phrase-table-source.txt
    python3 phrase_table_generation.py translationProbabilitySourceGivenTarget.txt ./Dataset/training_t.lm ./phrase-table-target.txt
}


function evaluate_model {
    ### Run the model on testset and Evaluate it using different error metrics ###
    echo "Evaluating the model..."
    
    export STANFORD_PARSER_HOME=/home/aman-anmol/Documents/3-II/StatisticalMethodsInAI/Assignments/machine-translator/src/utils/stanford-parser-full-2018-10-17
    ./utils/cfilt_preorder/reorderEnglish.sh Dataset/raw/testing_source.txt hindi_tuned
    cp Dataset/raw/testing_source.txt.codkilled.v1.0 Dataset/raw/testing_source.txt

    python3 decoder.py ./phrase-table-target.txt ./Dataset/raw/testing_source.txt 
    python3 evaluate_translations.py ./Dataset/raw/testing_target.txt ./translations.txt
}

# Parameter Checking 
if [ $# == 0 ] 
then 
    help_menu
    exit 0
fi

# Command Execution 
if [ "$1" == 'clean' ] 
then 
    clean_files

elif [ "$1" == 'generate' ] 
then 
    generate_data

elif [ "$1" == 'train' ] 
then 
    train_model

elif [ "$1" == 'test' ] 
then 
    evaluate_model

elif [ "$1" == 'build' ] 
then 
    clean_files
    generate_data
    train_model
    evaluate_model

elif [ "$1" == 'help' ] 
then 
    help_menu

else 
    echo "Usage: ./build.sh COMMAND"
    echo "Try \"./build.sh help\" for help."
    echo ""
    echo "Error: No such command \"$1\""
fi